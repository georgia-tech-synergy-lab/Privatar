{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizontal Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:113: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:135: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:113: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:135: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:113: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:135: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_365470/1813210002.py:113: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(x.shape[1] == 3, \"Wrong input, Channel should equals to 3\")\n",
      "/tmp/ipykernel_365470/1813210002.py:135: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(downsample_img.shape == freq_block[:,:,0,:,:].shape, \"downsample input shape does not match the shape of post-BDCT component\")\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from os import wait\n",
    "import os\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Custom Inserted\n",
    "from torchjpeg import dct\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# prefix_path_captured_latent_code = prefix_path_captured_latent_code_god2\n",
    "threshold_list = [0.1, 0.3, 0.35, 0.4, 0.42, 0.45, 0.5, 0.6, 0.7, 1.1, 1.2, 3.5, 5]\n",
    "\n",
    "# Select based on the difference of downsample input --- BDCT frequency block.\n",
    "all_private_selection = [[0],\n",
    "[0, 1],\n",
    "[0, 1, 2],\n",
    "[0, 1, 2, 3],\n",
    "[0, 1, 2, 3, 4],\n",
    "[0, 1, 2, 3, 4, 5],\n",
    "[0, 1, 2, 3, 4, 5, 6],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
    "\n",
    "all_possible_idx = [i for i in range(64)]\n",
    "selected_privacy_idx = -2\n",
    "\n",
    "private_idx = all_private_selection[selected_privacy_idx]\n",
    "public_idx = []\n",
    "\n",
    "for element in all_possible_idx:\n",
    "    if element not in private_idx:\n",
    "        public_idx.append(element)\n",
    "\n",
    "class DeepAppearanceVAE_Horizontal_Partition(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tex_size=1024,\n",
    "        mesh_inp_size=21918,\n",
    "        mode=\"vae\",\n",
    "        n_latent=128,\n",
    "        n_cams=38,\n",
    "        n_blocks=4,\n",
    "        frequency_threshold=19,\n",
    "        average_texture_path=\"/home/jianming/work/multiface/dataset/m--20180227--0000--6795937--GHS/unwrapped_uv_1024/E001_Neutral_Eyes_Open/average/000102.png\",\n",
    "        prefix_path_captured_latent_code=\"/home/jianming/work/Privatar_prj/testing_results/horizontal_partition_\",\n",
    "        path_variance_matrix_tensor=\"/usr/scratch/jianming/Privatar/profiled_latent_code/statistics/noise_variance_matrix_horizontal_partition_6.0_mutual_bound_1.pth\",\n",
    "        save_latent_code_to_external_device = False,\n",
    "        apply_gaussian_noise = True,\n",
    "        res=False,\n",
    "        non=False,\n",
    "        bilinear=False,\n",
    "    ):\n",
    "        super(DeepAppearanceVAE_Horizontal_Partition, self).__init__()\n",
    "        \n",
    "        z_dim = n_latent if mode == \"vae\" else n_latent * 2\n",
    "        self.mode = mode\n",
    "        self.interpolation_ratio = 2\n",
    "        tex_size = tex_size * self.interpolation_ratio // n_blocks \n",
    "        self.block_size = n_blocks\n",
    "        self.total_frequency_component = self.block_size * self.block_size\n",
    "        \n",
    "        self.frequency_threshold = frequency_threshold\n",
    "        self.private_idx, self.public_idx = self.private_freq_component_thres_based_selection(average_texture_path, frequency_threshold) # ToDo\n",
    "        \n",
    "        self.private_total_in_chnl = len(self.private_idx) * 3 # 3 indicates RGB three channels of each frequency broken down\n",
    "        self.public_total_in_chnl = len(self.public_idx) * 3 # 3 indicates RGB three channels of each frequency broken down\n",
    "        print(f\"public_total_in_chnl={self.public_total_in_chnl}, private_total_in_chnl={self.private_total_in_chnl}\")\n",
    "        self.enc = DeepApperanceEncoderChnlConfig(\n",
    "            tex_size, mesh_inp_size, n_latent=z_dim, n_in_chnl=self.private_total_in_chnl, res=res\n",
    "        )\n",
    "        self.dec = DeepAppearanceDecoderChnlConfig(\n",
    "            tex_size, mesh_inp_size, z_dim=z_dim, n_in_chnl=self.private_total_in_chnl, res=res, non=non, bilinear=bilinear\n",
    "        )\n",
    "        self.enc_outsource = DeepApperanceEncoderNoMeshChnlConfig(\n",
    "            tex_size, mesh_inp_size, n_latent=z_dim, n_in_chnl=self.public_total_in_chnl, res=res\n",
    "        )\n",
    "        self.dec_outsource = DeepAppearanceDecoderNoMeshChnlConfig(\n",
    "            tex_size, mesh_inp_size, z_dim=z_dim, n_in_chnl=self.public_total_in_chnl, res=res, non=non, bilinear=bilinear\n",
    "        )\n",
    "        self.cc = ColorCorrection(n_cams)\n",
    "        self.iter = 0\n",
    "        self.iter_outsource = 0\n",
    "        self.prefix_path_captured_latent_code = prefix_path_captured_latent_code\n",
    "        self.save_latent_code_to_external_device = save_latent_code_to_external_device\n",
    "        self.apply_gaussian_noise = apply_gaussian_noise\n",
    "        directory_being_created = f\"{self.prefix_path_captured_latent_code}{self.frequency_threshold}_latent_code\"\n",
    "        print(f\"create directory {directory_being_created}\")\n",
    "        if not os.path.exists(f\"{self.prefix_path_captured_latent_code}{self.frequency_threshold}_latent_code\"):\n",
    "            os.makedirs(f\"{self.prefix_path_captured_latent_code}{self.frequency_threshold}_latent_code\")\n",
    "\n",
    "        self.mean = np.zeros(256)\n",
    "        if apply_gaussian_noise:\n",
    "            self.variance_matrix_tensor = torch.load(path_variance_matrix_tensor).cpu()\n",
    "\n",
    "    def img_reorder(self, x, bs, ch, h, w):\n",
    "        x = (x + 1) / 2 * 255\n",
    "        assert(x.shape[1] == 3, \"Wrong input, Channel should equals to 3\")\n",
    "        x = dct.to_ycbcr(x)  # comvert RGB to YCBCR\n",
    "        x -= 128\n",
    "        x = x.view(bs * ch, 1, h, w)\n",
    "        x = F.unfold(x, kernel_size=(self.block_size, self.block_size), dilation=1, padding=0, stride=(self.block_size,self.block_size))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = x.view(bs, ch, -1, self.block_size, self.block_size)\n",
    "        return x\n",
    "    \n",
    "    ## Image reordering and testing\n",
    "    def img_inverse_reroder(self, coverted_img, bs, ch, h, w):\n",
    "        x = coverted_img.view(bs* ch, -1, self.total_frequency_component)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.fold(x, output_size=(h, w), kernel_size=(self.block_size,self.block_size), stride=(self.block_size,self.block_size))\n",
    "        x += 128\n",
    "        x = x.view(bs, ch, h, w)\n",
    "        x = dct.to_rgb(x)#.squeeze(0)\n",
    "        x = (x / 255.0) * 2 - 1\n",
    "        return x\n",
    "\n",
    "    def calculate_block_mse(self, downsample_in, freq_block):\n",
    "        downsample_img = transforms.Resize(size=int(downsample_in.shape[-1]/self.block_size))(downsample_in)\n",
    "        assert(downsample_img.shape == freq_block[:,:,0,:,:].shape, \"downsample input shape does not match the shape of post-BDCT component\")\n",
    "        loss_vector = torch.zeros(freq_block.shape[2])\n",
    "        for i in range(freq_block.shape[2]):\n",
    "            # calculate the MSE between each frequency components and given input downsampled images\n",
    "            loss_vector[i] = F.mse_loss(downsample_img, freq_block[:,:,i,:,:])\n",
    "        return loss_vector\n",
    "\n",
    "    def private_freq_component_thres_based_selection(self, img_path, mse_threshold):\n",
    "        # The original input image comes with it and I disable it to reduce the computation overhead.\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        x = transform(image).unsqueeze(0)\n",
    "\n",
    "        back_input = x\n",
    "        bs, ch, h, w = x.shape\n",
    "        block_num = h // self.block_size\n",
    "        x = self.img_reorder(x, bs, ch, h, w)\n",
    "        dct_block = dct.block_dct(x) # BDCT\n",
    "        dct_block_reorder = dct_block.view(bs, ch, block_num, block_num, self.total_frequency_component).permute(0, 1, 4, 2, 3) # into (bs, ch, 16, block_num, block_num)\n",
    "        loss_vector = self.calculate_block_mse(back_input, dct_block_reorder)\n",
    "        # Split all component based on the frequency\n",
    "        private_idx = torch.where(loss_vector > mse_threshold)[0]\n",
    "        public_idx = []\n",
    "        all_possible_idx = [i for i in range(self.total_frequency_component)]\n",
    "        for element in all_possible_idx:\n",
    "            if element not in private_idx:\n",
    "                public_idx.append(element)\n",
    "\n",
    "        return private_idx,  torch.Tensor(public_idx).to(torch.int64)\n",
    "\n",
    "    def forward(self, avgtex, mesh, view, cams=None):\n",
    "        # The mesh also needs to be partitioned by two sets of models\n",
    "        b, n, _ = mesh.shape\n",
    "        mesh = mesh.view((b, -1))\n",
    "        # process input avgtex\n",
    "        # avgtex_interpolate = F.interpolate(avgtex, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        # x = avgtex_interpolate\n",
    "        x = (avgtex + 1) / 2 * 255\n",
    "        if x.shape[1] != 3:\n",
    "            print(\"Wrong input, Channel should equals to 3\")\n",
    "            return\n",
    "        x = dct.to_ycbcr(x)  # comvert RGB to YCBCR\n",
    "        x -= 128\n",
    "        bs, ch, h, w = x.shape\n",
    "        block_num = h // self.block_size\n",
    "        x = x.view(bs * ch, 1, h, w)\n",
    "        x = F.unfold(x, kernel_size=(self.block_size, self.block_size), dilation=1, padding=0, stride=(self.block_size, self.block_size))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = x.view(bs, ch, -1, self.block_size, self.block_size)\n",
    "        dct_block = dct.block_dct(x) # BDCT\n",
    "        dct_block_reorder = dct_block.view(bs, ch, block_num, block_num, self.total_frequency_component).permute(0, 1, 4, 2, 3) # into (bs, ch, 64, block_num, block_num)\n",
    "        private_dct_block = dct_block_reorder[:,:,self.private_idx,:,:].view(bs, self.private_total_in_chnl, block_num, block_num)\n",
    "        public_dct_block = dct_block_reorder[:,:,self.public_idx,:,:].view(bs, self.public_total_in_chnl, block_num, block_num)\n",
    "        # Inserted Horizontal Parationing logic -- Done\n",
    "\n",
    "        # mean, logstd = self.enc(avgtex, mesh) # Comment out for enabling horizontal partitioning\n",
    "        mean, logstd = self.enc(private_dct_block, mesh)\n",
    "        mean = mean * 0.1\n",
    "        logstd = logstd * 0.01\n",
    "        if self.mode == \"vae\":\n",
    "            kl = 0.5 * torch.mean(torch.exp(2 * logstd) + mean**2 - 1.0 - 2 * logstd)\n",
    "            std = torch.exp(logstd)\n",
    "            eps = torch.randn_like(mean)\n",
    "            z = mean + std * eps\n",
    "        else:\n",
    "            z = torch.cat((mean, logstd), -1)\n",
    "            kl = torch.tensor(0).to(z.device)\n",
    "        \n",
    "        if self.save_latent_code_to_external_device:\n",
    "            path_captured_latent_code = f\"{self.prefix_path_captured_latent_code}{self.frequency_threshold}_latent_code\"\n",
    "            torch.save(logstd, f\"{path_captured_latent_code}/logstd_{self.iter}.pth\")\n",
    "            torch.save(mean, f\"{path_captured_latent_code}/mean_{self.iter}.pth\")\n",
    "            torch.save(z, f\"{path_captured_latent_code}/z_{self.iter}.pth\")\n",
    "            torch.save(kl, f\"{path_captured_latent_code}/kl_{self.iter}.pth\")\n",
    "            self.iter = self.iter + 1\n",
    "        \n",
    "        pred_tex_private, pred_mesh = self.dec(z, view)\n",
    "        pred_tex_private = pred_tex_private.view(bs, ch, -1, block_num, block_num)\n",
    "        \n",
    "        if self.public_idx != []:\n",
    "            mean_outsource, logstd_outsource = self.enc_outsource(public_dct_block)\n",
    "            mean_outsource = mean_outsource * 0.1\n",
    "            logstd_outsource = logstd_outsource * 0.01\n",
    "            if self.mode == \"vae\":\n",
    "                std_outsource = torch.exp(logstd_outsource)\n",
    "                eps_outsource = torch.randn_like(mean_outsource)\n",
    "                z_outsource = mean_outsource + std_outsource * eps_outsource\n",
    "            else:\n",
    "                z_outsource = torch.cat((mean_outsource, logstd_outsource), -1)\n",
    "            \n",
    "            # Adding model outsource encoder\n",
    "            if self.apply_gaussian_noise:\n",
    "                self.variance_matrix_tensor = self.variance_matrix_tensor.cpu()\n",
    "                samples = torch.from_numpy(np.random.multivariate_normal(self.mean, self.variance_matrix_tensor.detach().numpy(), z_outsource.shape[0]))\n",
    "                samples = samples.to(\"cuda:0\")\n",
    "                samples = samples.to(z_outsource.dtype)\n",
    "                z_outsource = z_outsource + samples\n",
    "\n",
    "            if self.save_latent_code_to_external_device:\n",
    "                path_captured_latent_code = f\"{self.prefix_path_captured_latent_code}{self.frequency_threshold}_latent_code\"\n",
    "                torch.save(logstd_outsource, f\"{path_captured_latent_code}/logstd_outsource_{self.iter_outsource}.pth\")\n",
    "                torch.save(mean_outsource, f\"{path_captured_latent_code}/mean_outsource_{self.iter_outsource}.pth\")\n",
    "                torch.save(z_outsource, f\"{path_captured_latent_code}/z_outsource_{self.iter_outsource}.pth\")\n",
    "                self.iter_outsource = self.iter_outsource + 1\n",
    "            \n",
    "            pred_tex_outsource = self.dec_outsource(z_outsource, view)\n",
    "            pred_tex_outsource = pred_tex_outsource.view(bs, ch, -1, block_num, block_num)\n",
    "            # Adding model outsource encoder -- Done\n",
    "\n",
    "        # Adding block reconstructions\n",
    "        pred_tex = torch.zeros(bs, ch, self.total_frequency_component, block_num, block_num).to(pred_tex_private.device)\n",
    "\n",
    "        for i, idx in enumerate(self.private_idx):\n",
    "            pred_tex[:, :, idx, :, :] = pred_tex_private[:, :, i, :, :]\n",
    "        for i, idx in enumerate(self.public_idx):\n",
    "            pred_tex[:, :, idx, :, :] = pred_tex_outsource[:, :, i, :, :]\n",
    "        \n",
    "        # Adding block reconstructions -- Done\n",
    "        # # reorder to revert the layout\n",
    "        idct_dct_block_reorder = pred_tex.view(bs, ch, self.total_frequency_component, block_num*block_num).permute(0, 1, 3, 2).view(bs, ch, block_num*block_num, self.block_size, self.block_size)\n",
    "\n",
    "        idct_dct_block = dct.block_idct(idct_dct_block_reorder) #inverse BDCT\n",
    "\n",
    "        ## Reconstruct the overall original input image\n",
    "        pred_tex = self.img_inverse_reroder(idct_dct_block, bs, ch, h, w)\n",
    "        pred_tex = transforms.Resize(size=1024)(pred_tex)\n",
    "        pred_mesh = pred_mesh.view((b, n, 3))\n",
    "        if cams is not None:\n",
    "            pred_tex = self.cc(pred_tex, cams)\n",
    "\n",
    "        return pred_tex, pred_mesh, kl\n",
    "\n",
    "    def get_mesh_branch_params(self):\n",
    "        p = self.enc.get_mesh_branch_params() + self.dec.get_mesh_branch_params()\n",
    "        return p\n",
    "\n",
    "    def get_tex_branch_params(self):\n",
    "        p = self.enc.get_tex_branch_params() + self.dec.get_tex_branch_params()\n",
    "        return p\n",
    "\n",
    "    def get_model_params(self):\n",
    "        params = []\n",
    "        params += list(self.enc.parameters())\n",
    "        params += list(self.dec.parameters())\n",
    "        return params\n",
    "\n",
    "    def get_cc_params(self):\n",
    "        return self.cc.parameters()\n",
    "\n",
    "\n",
    "class WarpFieldDecoder(nn.Module):\n",
    "    def __init__(self, tex_size=1024, z_dim=128):\n",
    "        super(WarpFieldDecoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            LinearWN(z_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            LinearWN(256, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            ConvUpsample(256, 128, 128, 2),\n",
    "            ConvUpsample(128, 128, 64, 2 * (2**2)),\n",
    "            ConvUpsample(64, 64, 32, 2 * (2**4)),\n",
    "            ConvUpsample(32, 32, 16, 2 * (2**6)),\n",
    "            nn.Upsample(size=tex_size, mode='bilinear'),\n",
    "            nn.Conv2d(16, 2, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "        self.apply(lambda x: glorot(x, 0.2))\n",
    "        glorot(self.upsample[-1], 1.0)\n",
    "\n",
    "        self.tex_size = tex_size\n",
    "\n",
    "        xgrid, ygrid = np.meshgrid(np.linspace(-1.0, 1.0, tex_size), np.linspace(-1.0, 1.0, tex_size))\n",
    "        grid = np.concatenate((xgrid[None, :, :], ygrid[None, :, :]), axis=0)[None, ...].astype(np.float32)\n",
    "        self.register_buffer(\"normal_grid\", torch.from_numpy(grid))\n",
    "\n",
    "    def forward(self, z, img):\n",
    "        b, c, h, w = img.shape\n",
    "\n",
    "        feat = self.mlp(z).view((-1, 256, 2, 2))\n",
    "        warp = self.upsample(feat) / self.tex_size\n",
    "        grid = warp + self.normal_grid\n",
    "        if grid.shape[2] < img.shape[2]:\n",
    "            grid = F.interpolate(grid, scale_factor=img.shape[2] / grid.shape[2])\n",
    "        grid = grid.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        out = F.grid_sample(img, grid)\n",
    "        return out, grid\n",
    "\n",
    "\n",
    "class DeepAppearanceDecoderChnlConfig(nn.Module):\n",
    "    def __init__(\n",
    "        self, tex_size, mesh_size, z_dim=128, n_in_chnl=3, res=False, non=False, bilinear=False\n",
    "    ):\n",
    "        super(DeepAppearanceDecoderChnlConfig, self).__init__()\n",
    "        nhidden = z_dim * 4 * 4 # if tex_size == 1024 else z_dim * 2 * 2\n",
    "        self.texture_decoder = TextureDecoder_Chnl_Config(\n",
    "            tex_size, z_dim, n_in_chnl, res=res, non=non, bilinear=bilinear\n",
    "        )\n",
    "        self.view_fc = LinearWN(3, 8)\n",
    "        self.z_fc = LinearWN(z_dim, 256)\n",
    "        self.mesh_fc = LinearWN(256, mesh_size)\n",
    "        self.texture_fc = LinearWN(256 + 8, nhidden)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.apply(lambda x: glorot(x, 0.2))\n",
    "        glorot(self.mesh_fc, 1.0)\n",
    "        glorot(self.texture_decoder.upsample[-1].conv2, 1.0)\n",
    "\n",
    "    def forward(self, z, v):\n",
    "        view_code = self.relu(self.view_fc(v))\n",
    "        z_code = self.relu(self.z_fc(z))\n",
    "        feat = torch.cat((view_code, z_code), 1)\n",
    "        texture_code = self.relu(self.texture_fc(feat))\n",
    "        texture = self.texture_decoder(texture_code)\n",
    "        mesh = self.mesh_fc(z_code)\n",
    "        return texture, mesh\n",
    "\n",
    "    def get_mesh_branch_params(self):\n",
    "        return list(self.mesh_fc.parameters())\n",
    "\n",
    "    def get_tex_branch_params(self):\n",
    "        p = []\n",
    "        p += list(self.texture_decoder.parameters())\n",
    "        p += list(self.view_fc.parameters())\n",
    "        p += list(self.z_fc.parameters())\n",
    "        p += list(self.texture_fc.parameters())\n",
    "        return p\n",
    "\n",
    "\n",
    "class DeepApperanceEncoderNoMeshChnlConfig(nn.Module):\n",
    "    def __init__(self, inp_size=1024, mesh_inp_size=21918, n_latent=128, n_in_chnl=3, res=False):\n",
    "        super(DeepApperanceEncoderNoMeshChnlConfig, self).__init__()\n",
    "        self.n_latent = n_latent\n",
    "        ntexture_feat = 2048 #if inp_size == 1024 else 512\n",
    "        self.texture_encoder = TextureEncoder_Chnl_Config(n_in_chnl=n_in_chnl, res=res)\n",
    "        self.texture_fc = LinearWN(ntexture_feat, 256)\n",
    "        # self.fc = LinearWN(512, n_latent * 2) # Horizontal Partitioning Modification (Remove Mesh and corresponding input channels from 512 -> 256)\n",
    "        self.fc = LinearWN(256, n_latent * 2)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.apply(lambda x: glorot(x, 0.2))\n",
    "        glorot(self.fc, 1.0)\n",
    "\n",
    "    def forward(self, tex):\n",
    "        tex_feat = self.relu(self.texture_fc(self.texture_encoder(tex)))\n",
    "        latent = self.fc(tex_feat)\n",
    "        return latent[:, : self.n_latent], latent[:, self.n_latent :]\n",
    "\n",
    "    def get_tex_branch_params(self):\n",
    "        p = []\n",
    "        p += list(self.texture_encoder.parameters())\n",
    "        p += list(self.texture_fc.parameters())\n",
    "        p += list(self.fc.parameters())\n",
    "        return p\n",
    "    \n",
    "\n",
    "class DeepApperanceEncoderChnlConfig(nn.Module):\n",
    "    def __init__(self, inp_size=1024, mesh_inp_size=21918, n_latent=128, n_in_chnl=3, res=False):\n",
    "        super(DeepApperanceEncoderChnlConfig, self).__init__()\n",
    "        self.n_latent = n_latent\n",
    "        # ntexture_feat = 2048 if inp_size == 1024 else 512\n",
    "        ntexture_feat = 2048 #if inp_size == 1024 else 128\n",
    "        self.texture_encoder = TextureEncoder_Chnl_Config(n_in_chnl=n_in_chnl, res=res)\n",
    "        self.texture_fc = LinearWN(ntexture_feat, 256)\n",
    "        self.mesh_fc = LinearWN(mesh_inp_size, 256)\n",
    "        self.fc = LinearWN(512, n_latent * 2)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.apply(lambda x: glorot(x, 0.2))\n",
    "        glorot(self.fc, 1.0)\n",
    "\n",
    "    def forward(self, tex, mesh):\n",
    "        tex_feat = self.relu(self.texture_fc(self.texture_encoder(tex)))\n",
    "        mesh_feat = self.relu(self.mesh_fc(mesh))\n",
    "        feat = torch.cat((tex_feat, mesh_feat), -1)\n",
    "        latent = self.fc(feat)\n",
    "        return latent[:, : self.n_latent], latent[:, self.n_latent :]\n",
    "\n",
    "    def get_mesh_branch_params(self):\n",
    "        return list(self.mesh_fc.parameters())\n",
    "\n",
    "    def get_tex_branch_params(self):\n",
    "        p = []\n",
    "        p += list(self.texture_encoder.parameters())\n",
    "        p += list(self.texture_fc.parameters())\n",
    "        p += list(self.fc.parameters())\n",
    "        return p\n",
    "\n",
    "\n",
    "class DeepAppearanceDecoderNoMeshChnlConfig(nn.Module):\n",
    "    def __init__(\n",
    "        self, tex_size, mesh_size, z_dim=128, n_in_chnl=3, res=False, non=False, bilinear=False\n",
    "    ):\n",
    "        super(DeepAppearanceDecoderNoMeshChnlConfig, self).__init__()\n",
    "        nhidden = z_dim * 4 * 4 #if tex_size == 1024 else z_dim * 2 * 2\n",
    "        self.texture_decoder = TextureDecoder_Chnl_Config(\n",
    "            tex_size, z_dim, n_in_chnl=n_in_chnl, res=res, non=non, bilinear=bilinear\n",
    "        )\n",
    "        self.view_fc = LinearWN(3, 8)\n",
    "        self.z_fc = LinearWN(z_dim, 256)\n",
    "        self.texture_fc = LinearWN(256 + 8, nhidden)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.apply(lambda x: glorot(x, 0.2))\n",
    "        glorot(self.texture_decoder.upsample[-1].conv2, 1.0)\n",
    "\n",
    "    def forward(self, z, v):\n",
    "        view_code = self.relu(self.view_fc(v))\n",
    "        z_code = self.relu(self.z_fc(z))\n",
    "        feat = torch.cat((view_code, z_code), 1)\n",
    "        texture_code = self.relu(self.texture_fc(feat))\n",
    "        texture = self.texture_decoder(texture_code)\n",
    "        return texture\n",
    "\n",
    "    def get_tex_branch_params(self):\n",
    "        p = []\n",
    "        p += list(self.texture_decoder.parameters())\n",
    "        p += list(self.view_fc.parameters())\n",
    "        p += list(self.z_fc.parameters())\n",
    "        p += list(self.texture_fc.parameters())\n",
    "        return p\n",
    "\n",
    "\n",
    "class TextureDecoder(nn.Module):\n",
    "    def __init__(self, tex_size, z_dim, res=False, non=False, bilinear=False):\n",
    "        super(TextureDecoder, self).__init__()\n",
    "        base = 2 if tex_size == 512 else 4\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            ConvUpsample(\n",
    "                z_dim, z_dim, 64, base, res=res, use_bilinear=bilinear, non=non\n",
    "            ),\n",
    "            ConvUpsample(\n",
    "                64, 64, 32, base * (2**2), res=res, use_bilinear=bilinear, non=non\n",
    "            ),\n",
    "            ConvUpsample(\n",
    "                32, 32, 16, base * (2**4), res=res, use_bilinear=bilinear, non=non\n",
    "            ),\n",
    "            ConvUpsample(\n",
    "                16,\n",
    "                16,\n",
    "                3,\n",
    "                base * (2**6),\n",
    "                no_activ=True,\n",
    "                res=res,\n",
    "                use_bilinear=bilinear,\n",
    "                non=non,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n = x.shape\n",
    "        h = int(np.sqrt(n / self.z_dim))\n",
    "        x = x.view((-1, self.z_dim, h, h))\n",
    "        out = self.upsample(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TextureEncoder(nn.Module):\n",
    "    def __init__(self, res=False):\n",
    "        super(TextureEncoder, self).__init__()\n",
    "        self.downsample = nn.Sequential(\n",
    "            ConvDownsample(3, 16, 16, res=res),\n",
    "            ConvDownsample(16, 32, 32, res=res),\n",
    "            ConvDownsample(32, 64, 64, res=res),\n",
    "            ConvDownsample(64, 128, 128, res=res),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        feat = self.downsample(x)\n",
    "        out = feat.view((b, -1))\n",
    "        return out\n",
    "\n",
    "\n",
    "class TextureEncoder_Chnl_Config(nn.Module):\n",
    "    def __init__(self, n_in_chnl=3, res=False):\n",
    "        super(TextureEncoder_Chnl_Config, self).__init__()\n",
    "        self.downsample = nn.Sequential(\n",
    "            # ConvDownsample(n_in_chnl, 16, 16, res=res),\n",
    "            # ConvDownsampleSglConv(n_in_chnl, 32, 32, res=res),\n",
    "            ConvDownsample(n_in_chnl, 32, 32, res=res),\n",
    "            ConvDownsample(32, 64, 64, res=res),\n",
    "            ConvDownsample(64, 128, 128, res=res),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        feat = self.downsample(x)\n",
    "        out = feat.view((b, -1))\n",
    "        return out\n",
    "\n",
    "class TextureDecoder_Chnl_Config(nn.Module):\n",
    "    def __init__(self, tex_size, z_dim, n_in_chnl, res=False, non=False, bilinear=False):\n",
    "        super(TextureDecoder_Chnl_Config, self).__init__()\n",
    "        base = 4# if tex_size == 512 else 4\n",
    "        # base = 2 if tex_size == 512 else 4\n",
    "        self.z_dim = z_dim\n",
    "        if bilinear:\n",
    "            print(\"user bilinear\")\n",
    "        self.upsample = nn.Sequential(\n",
    "            ConvUpsample(\n",
    "                z_dim, z_dim, 64, base, res=res, use_bilinear=bilinear, non=non\n",
    "            ),\n",
    "            ConvUpsample(\n",
    "                64, 64, 32, base * (2**2), res=res, use_bilinear=bilinear, non=non\n",
    "            ),\n",
    "            # ConvUpsample(\n",
    "            #     32, 32, 16, base * (2**4), res=res, use_bilinear=bilinear, non=non\n",
    "            # ),\n",
    "            ConvUpsample(\n",
    "                32,\n",
    "                32,\n",
    "                n_in_chnl,\n",
    "                base * (2**4),\n",
    "                no_activ=True,\n",
    "                res=res,\n",
    "                use_bilinear=bilinear,\n",
    "                non=non,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n = x.shape\n",
    "        h = int(np.sqrt(n / self.z_dim))\n",
    "        x = x.view((-1, self.z_dim, h, h))\n",
    "        out = self.upsample(x)\n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, nin, nhidden, nout):\n",
    "        self.fc1 = LinearWN(nin, nhidden)\n",
    "        self.fc2 = LinearWN(nhidden, nout)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvDownsampleSglConv(nn.Module):\n",
    "    def __init__(self, cin, chidden, cout, res=False):\n",
    "        super(ConvDownsampleSglConv, self).__init__()\n",
    "        self.conv1 = Conv2dWN(cin, cout, 4, 2, padding=1)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.conv1(x))\n",
    "        return h\n",
    "    \n",
    "class ConvDownsample(nn.Module):\n",
    "    def __init__(self, cin, chidden, cout, res=False):\n",
    "        super(ConvDownsample, self).__init__()\n",
    "        self.conv1 = Conv2dWN(cin, chidden, 4, 2, padding=1)\n",
    "        self.conv2 = Conv2dWN(chidden, cout, 4, 2, padding=1)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.res = res\n",
    "        if res:\n",
    "            self.res1 = Conv2dWN(chidden, chidden, 3, 1, 1)\n",
    "            self.res2 = Conv2dWN(cout, cout, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.conv1(x))\n",
    "        if self.res:\n",
    "            h = self.relu(self.res1(h) + h)\n",
    "        h = self.relu(self.conv2(h))\n",
    "        if self.res:\n",
    "            h = self.relu(self.res2(h) + h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class ConvUpsampleSglConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cin,\n",
    "        chidden,\n",
    "        cout,\n",
    "        feature_size,\n",
    "        no_activ=False,\n",
    "        res=False,\n",
    "        use_bilinear=False,\n",
    "        non=False,\n",
    "    ):\n",
    "        super(ConvUpsampleSglConv, self).__init__()\n",
    "        self.conv2 = DeconvTexelBias(\n",
    "            chidden, cout, feature_size * 2, use_bilinear=use_bilinear, non=non\n",
    "        )\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.no_activ = no_activ\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.no_activ:\n",
    "            h = self.conv2(x)\n",
    "        else:\n",
    "            h = self.relu(self.conv2(x))\n",
    "        return h\n",
    "    \n",
    "class ConvUpsample(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cin,\n",
    "        chidden,\n",
    "        cout,\n",
    "        feature_size,\n",
    "        no_activ=False,\n",
    "        res=False,\n",
    "        use_bilinear=False,\n",
    "        non=False,\n",
    "    ):\n",
    "        super(ConvUpsample, self).__init__()\n",
    "        self.conv1 = DeconvTexelBias(\n",
    "            cin, chidden, feature_size * 2, use_bilinear=use_bilinear, non=non\n",
    "        )\n",
    "        self.conv2 = DeconvTexelBias(\n",
    "            chidden, cout, feature_size * 4, use_bilinear=use_bilinear, non=non\n",
    "        )\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.no_activ = no_activ\n",
    "        self.res = res\n",
    "        if self.res:\n",
    "            self.res1 = Conv2dWN(chidden, chidden, 3, 1, 1)\n",
    "            self.res2 = Conv2dWN(cout, cout, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.conv1(x))\n",
    "        if self.res:\n",
    "            h = self.relu(self.res1(h) + h)\n",
    "        if self.no_activ:\n",
    "            h = self.conv2(h)\n",
    "            if self.res:\n",
    "                h = self.res2(h) + h\n",
    "        else:\n",
    "            h = self.relu(self.conv2(h))\n",
    "            if self.res:\n",
    "                h = self.relu(self.res2(h) + h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class DeconvTexelBias(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cin,\n",
    "        cout,\n",
    "        feature_size,\n",
    "        ksize=4,\n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        use_bilinear=False,\n",
    "        non=False,\n",
    "    ):\n",
    "        super(DeconvTexelBias, self).__init__()\n",
    "        if isinstance(feature_size, int):\n",
    "            feature_size = (feature_size, feature_size)\n",
    "        self.use_bilinear = use_bilinear\n",
    "        if use_bilinear:\n",
    "            self.deconv = Conv2dWN(cin, cout, 3, 1, 1, bias=False)\n",
    "        else:\n",
    "            self.deconv = ConvTranspose2dWN(\n",
    "                cin, cout, ksize, stride, padding, bias=False\n",
    "            )\n",
    "        if non:\n",
    "            self.bias = nn.Parameter(torch.zeros(1, cout, 1, 1))\n",
    "        else:\n",
    "            self.bias = nn.Parameter(\n",
    "                torch.zeros(1, cout, feature_size[0], feature_size[1])\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bilinear:\n",
    "            x = F.interpolate(x, scale_factor=2)\n",
    "        out = self.deconv(x) + self.bias\n",
    "        return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "class ColorCorrection(nn.Module):\n",
    "    def __init__(self, n_cameras, nc=3):\n",
    "        super(ColorCorrection, self).__init__()\n",
    "        weights = torch.zeros(n_cameras, nc, nc, 1, 1)\n",
    "        for i in range(nc):\n",
    "            weights[:, i, i] = 1\n",
    "        self.weights = nn.Parameter(weights)\n",
    "        self.bias = nn.Parameter(torch.zeros(n_cameras, nc))\n",
    "        self.anchor = 0\n",
    "    def forward(self, texture, cam):\n",
    "        b, c, h, w = texture.shape\n",
    "        texture = texture.view(1, b*c, h, w)\n",
    "        weight = self.weights[cam]\n",
    "        bias = self.bias[cam]\n",
    "        if self.training:\n",
    "            weight[cam == self.anchor] = torch.eye(3).view(3, 3, 1, 1).to(texture.device)\n",
    "            bias[cam == self.anchor] = 0\n",
    "        weight = weight.view(b*c, 3, 1, 1)\n",
    "        bias = bias.view(b*c)\n",
    "        out = F.conv2d(texture, weight, bias, groups=b).view(b, c, h, w)\n",
    "        return out\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ColorCorrection(nn.Module):\n",
    "    def __init__(self, n_cameras, nc=3):\n",
    "        super(ColorCorrection, self).__init__()\n",
    "        # anchors the 0th camera\n",
    "        self.weight_anchor = nn.Parameter(torch.ones(1, nc, 1, 1), requires_grad=False)\n",
    "        self.bias_anchor = nn.Parameter(torch.zeros(1, 3, 1, 1), requires_grad=False)\n",
    "        self.weight = nn.Parameter(torch.ones(n_cameras - 1, 3, 1, 1))\n",
    "        self.bias = nn.Parameter(torch.zeros(n_cameras - 1, 3, 1, 1))\n",
    "\n",
    "    def forward(self, texture, cam):\n",
    "        weights = torch.cat([self.weight_anchor, self.weight], dim=0)\n",
    "        biases = torch.cat([self.bias_anchor, self.bias], dim=0)\n",
    "        w = weights[cam]\n",
    "        b = biases[cam]\n",
    "        output = texture * w + b\n",
    "        return output\n",
    "\n",
    "\n",
    "def glorot(m, alpha):\n",
    "    gain = math.sqrt(2.0 / (1.0 + alpha**2))\n",
    "\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        ksize = m.kernel_size[0] * m.kernel_size[1]\n",
    "        n1 = m.in_channels\n",
    "        n2 = m.out_channels\n",
    "\n",
    "        std = gain * math.sqrt(2.0 / ((n1 + n2) * ksize))\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        ksize = m.kernel_size[0] * m.kernel_size[1] // 4\n",
    "        n1 = m.in_channels\n",
    "        n2 = m.out_channels\n",
    "\n",
    "        std = gain * math.sqrt(2.0 / ((n1 + n2) * ksize))\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        n1 = m.in_features\n",
    "        n2 = m.out_features\n",
    "\n",
    "        std = gain * math.sqrt(2.0 / (n1 + n2))\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    # m.weight.data.normal_(0, std)\n",
    "    m.weight.data.uniform_(-std * math.sqrt(3.0), std * math.sqrt(3.0))\n",
    "    m.bias.data.zero_()\n",
    "\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        # hardcoded for stride=2 for now\n",
    "        m.weight.data[:, :, 0::2, 1::2] = m.weight.data[:, :, 0::2, 0::2]\n",
    "        m.weight.data[:, :, 1::2, 0::2] = m.weight.data[:, :, 0::2, 0::2]\n",
    "        m.weight.data[:, :, 1::2, 1::2] = m.weight.data[:, :, 0::2, 0::2]\n",
    "\n",
    "    # if isinstance(m, Conv2dWNUB) or isinstance(m, ConvTranspose2dWNUB) or isinstance(m, LinearWN):\n",
    "    if (\n",
    "        isinstance(m, Conv2dWNUB)\n",
    "        or isinstance(m, Conv2dWN)\n",
    "        or isinstance(m, ConvTranspose2dWN)\n",
    "        or isinstance(m, ConvTranspose2dWNUB)\n",
    "        or isinstance(m, LinearWN)\n",
    "    ):\n",
    "        norm = np.sqrt(torch.sum(m.weight.data[:] ** 2))\n",
    "        m.g.data[:] = norm\n",
    "\n",
    "\n",
    "class LinearWN(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(LinearWN, self).__init__(in_features, out_features, bias)\n",
    "        self.g = nn.Parameter(torch.ones(out_features))\n",
    "\n",
    "    def forward(self, input):\n",
    "        wnorm = torch.sqrt(torch.sum(self.weight**2))\n",
    "        return F.linear(input, self.weight * self.g[:, None] / wnorm, self.bias)\n",
    "\n",
    "\n",
    "class Conv2dWNUB(nn.Conv2d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        height,\n",
    "        width,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=False,\n",
    "    ):\n",
    "        super(Conv2dWNUB, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            groups,\n",
    "            False,\n",
    "        )\n",
    "        self.g = nn.Parameter(torch.ones(out_channels))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels, height, width))\n",
    "\n",
    "    def forward(self, x):\n",
    "        wnorm = torch.sqrt(torch.sum(self.weight**2))\n",
    "        return (\n",
    "            F.conv2d(\n",
    "                x,\n",
    "                self.weight * self.g[:, None, None, None] / wnorm,\n",
    "                bias=None,\n",
    "                stride=self.stride,\n",
    "                padding=self.padding,\n",
    "                dilation=self.dilation,\n",
    "                groups=self.groups,\n",
    "            )\n",
    "            + self.bias[None, ...]\n",
    "        )\n",
    "\n",
    "\n",
    "class Conv2dWN(nn.Conv2d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=True,\n",
    "    ):\n",
    "        super(Conv2dWN, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            groups,\n",
    "            True,\n",
    "        )\n",
    "        self.g = nn.Parameter(torch.ones(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        wnorm = torch.sqrt(torch.sum(self.weight**2))\n",
    "        return F.conv2d(\n",
    "            x,\n",
    "            self.weight * self.g[:, None, None, None] / wnorm,\n",
    "            bias=self.bias,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "            dilation=self.dilation,\n",
    "            groups=self.groups,\n",
    "        )\n",
    "\n",
    "\n",
    "class ConvTranspose2dWNUB(nn.ConvTranspose2d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        height,\n",
    "        width,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=False,\n",
    "    ):\n",
    "        super(ConvTranspose2dWNUB, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            groups,\n",
    "            False,\n",
    "        )\n",
    "        self.g = nn.Parameter(torch.ones(out_channels))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels, height, width))\n",
    "\n",
    "    def forward(self, x):\n",
    "        wnorm = torch.sqrt(torch.sum(self.weight**2))\n",
    "        return (\n",
    "            F.conv_transpose2d(\n",
    "                x,\n",
    "                self.weight * self.g[None, :, None, None] / wnorm,\n",
    "                bias=None,\n",
    "                stride=self.stride,\n",
    "                padding=self.padding,\n",
    "                dilation=self.dilation,\n",
    "                groups=self.groups,\n",
    "            )\n",
    "            + self.bias[None, ...]\n",
    "        )\n",
    "\n",
    "\n",
    "class ConvTranspose2dWN(nn.ConvTranspose2d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=True,\n",
    "    ):\n",
    "        super(ConvTranspose2dWN, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            groups,\n",
    "            True,\n",
    "        )\n",
    "        self.g = nn.Parameter(torch.ones(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        wnorm = torch.sqrt(torch.sum(self.weight**2))\n",
    "        return F.conv_transpose2d(\n",
    "            x,\n",
    "            self.weight * self.g[None, :, None, None] / wnorm,\n",
    "            bias=self.bias,\n",
    "            stride=self.stride,\n",
    "            padding=self.padding,\n",
    "            dilation=self.dilation,\n",
    "            groups=self.groups,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchanalyse import profiler, System, Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public_total_in_chnl=3, private_total_in_chnl=45\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.3_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "754.97472\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "3019.89888\n",
      "Outsourced Path Encoder\n",
      "50.331648\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "201.326592\n",
      "public_total_in_chnl=6, private_total_in_chnl=42\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.305_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "704.643072\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2818.572288\n",
      "Outsourced Path Encoder\n",
      "100.663296\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "402.653184\n",
      "public_total_in_chnl=9, private_total_in_chnl=39\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.35_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "654.311424\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2617.245696\n",
      "Outsourced Path Encoder\n",
      "150.994944\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "603.979776\n",
      "public_total_in_chnl=12, private_total_in_chnl=36\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.4_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "603.979776\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2415.919104\n",
      "Outsourced Path Encoder\n",
      "201.326592\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "805.306368\n",
      "public_total_in_chnl=15, private_total_in_chnl=33\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.42_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "553.648128\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2214.592512\n",
      "Outsourced Path Encoder\n",
      "251.65824\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1006.63296\n",
      "public_total_in_chnl=18, private_total_in_chnl=30\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.45_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "503.31648\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2013.26592\n",
      "Outsourced Path Encoder\n",
      "301.989888\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1207.959552\n",
      "public_total_in_chnl=21, private_total_in_chnl=27\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.5_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "452.984832\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1811.939328\n",
      "Outsourced Path Encoder\n",
      "352.321536\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1409.286144\n",
      "public_total_in_chnl=24, private_total_in_chnl=24\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.6_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "402.653184\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1610.612736\n",
      "Outsourced Path Encoder\n",
      "402.653184\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1610.612736\n",
      "public_total_in_chnl=27, private_total_in_chnl=21\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.63_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "352.321536\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1409.286144\n",
      "Outsourced Path Encoder\n",
      "452.984832\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1811.939328\n",
      "public_total_in_chnl=30, private_total_in_chnl=18\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_0.7_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "301.989888\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1207.959552\n",
      "Outsourced Path Encoder\n",
      "503.31648\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2013.26592\n",
      "public_total_in_chnl=30, private_total_in_chnl=18\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_1.035_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "301.989888\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "1207.959552\n",
      "Outsourced Path Encoder\n",
      "503.31648\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2013.26592\n",
      "public_total_in_chnl=36, private_total_in_chnl=12\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_1.1_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "201.326592\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "805.306368\n",
      "Outsourced Path Encoder\n",
      "603.979776\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2415.919104\n",
      "public_total_in_chnl=39, private_total_in_chnl=9\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_1.2_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "150.994944\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "603.979776\n",
      "Outsourced Path Encoder\n",
      "654.311424\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2617.245696\n",
      "public_total_in_chnl=42, private_total_in_chnl=6\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_3.5_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "100.663296\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "402.653184\n",
      "Outsourced Path Encoder\n",
      "704.643072\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "2818.572288\n",
      "public_total_in_chnl=45, private_total_in_chnl=3\n",
      "create directory /home/jianming/work/Privatar_prj/testing_results/horizontal_partition_5_latent_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::einsum\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sub_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::im2col\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::ones\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::copy_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::sqrt\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::leaky_relu_\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::exp\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::randn_like\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "/home/jianming/conda/envs/pica37/lib/python3.7/site-packages/torchanalyse-0.0.4-py3.7.egg/torchanalyse/profile.py:39: UserWarning: No handlers found: \"aten::col2im\". Skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op Type</th>\n",
       "      <th>Operator A</th>\n",
       "      <th>Operator B</th>\n",
       "      <th>Output</th>\n",
       "      <th>Bound</th>\n",
       "      <th>C/M ratio</th>\n",
       "      <th>Op Intensity</th>\n",
       "      <th>Latency (msec)</th>\n",
       "      <th>Cycles</th>\n",
       "      <th>C Effcy</th>\n",
       "      <th>Flops (MFLOP)</th>\n",
       "      <th>Input_a (MB)</th>\n",
       "      <th>Input_w (MB)</th>\n",
       "      <th>Output (MB)</th>\n",
       "      <th>Total Data (MB)</th>\n",
       "      <th>Throughput (Tflops)</th>\n",
       "      <th>Compute Cycles</th>\n",
       "      <th>Memory Cycles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::matmul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.050133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 1]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>[1, 3, 65536, 4, 4]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.154622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291457</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>aten::upsample_bilinear2d</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.152533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.165824</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2956.98432</td>\n",
       "      <td>13142.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>aten::mul</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>[1, 3, 1, 1]</td>\n",
       "      <td>[1, 3, 1024, 1024]</td>\n",
       "      <td>M</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.013981</td>\n",
       "      <td>13142.1588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.291456</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.145728</td>\n",
       "      <td>6.291459</td>\n",
       "      <td>0.45</td>\n",
       "      <td>48.081046</td>\n",
       "      <td>13142.1588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Op Type          Operator A           Operator B  \\\n",
       "0                    aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "1                    aten::mul                   1                    1   \n",
       "2                 aten::matmul              [4, 1]               [1, 4]   \n",
       "3                    aten::mul              [4, 1]                    1   \n",
       "4                    aten::mul              [1, 4]                    1   \n",
       "..                         ...                 ...                  ...   \n",
       "146                  aten::mul                   1  [1, 3, 65536, 4, 4]   \n",
       "147                  aten::mul                   1                    1   \n",
       "148                  aten::mul  [1, 3, 1024, 1024]                    1   \n",
       "149  aten::upsample_bilinear2d  [1, 3, 1024, 1024]                    0   \n",
       "150                  aten::mul  [1, 3, 1024, 1024]         [1, 3, 1, 1]   \n",
       "\n",
       "                  Output Bound C/M ratio Op Intensity Latency (msec)  \\\n",
       "0     [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "1                      1     M  0.002439     0.333333            0.0   \n",
       "2                 [4, 4]     M  0.004878     0.666667            0.0   \n",
       "3                 [4, 1]     M  0.003252     0.444444            0.0   \n",
       "4                 [1, 4]     M  0.003252     0.444444            0.0   \n",
       "..                   ...   ...       ...          ...            ...   \n",
       "146  [1, 3, 65536, 4, 4]     M  0.003659          0.5       0.013981   \n",
       "147                    1     M  0.002439     0.333333            0.0   \n",
       "148   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "149   [1, 3, 1024, 1024]     M     0.225          2.0       0.013981   \n",
       "150   [1, 3, 1024, 1024]     M  0.003659          0.5       0.013981   \n",
       "\n",
       "           Cycles C Effcy Flops (MFLOP) Input_a (MB) Input_w (MB) Output (MB)  \\\n",
       "0    13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "1        0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "2        0.050133     1.0      0.000032     0.000004     0.000004    0.000016   \n",
       "3          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "4          0.0188     1.0      0.000008     0.000004     0.000001    0.000004   \n",
       "..            ...     ...           ...          ...          ...         ...   \n",
       "146  13142.154622     1.0      6.291456     0.000001     3.145728    3.145728   \n",
       "147      0.006267     1.0      0.000002     0.000001     0.000001    0.000001   \n",
       "148  13142.154622     1.0      6.291456     3.145728     0.000001    3.145728   \n",
       "149  13142.152533     1.0     25.165824     3.145728          0.0    3.145728   \n",
       "150    13142.1588     1.0      6.291456     3.145728     0.000003    3.145728   \n",
       "\n",
       "    Total Data (MB) Throughput (Tflops) Compute Cycles Memory Cycles  \n",
       "0          6.291457                0.45      48.081046  13142.154622  \n",
       "1          0.000003                 0.3       0.000015      0.006267  \n",
       "2          0.000024                 0.6       0.000245      0.050133  \n",
       "3          0.000009                 0.4       0.000061        0.0188  \n",
       "4          0.000009                 0.4       0.000061        0.0188  \n",
       "..              ...                 ...            ...           ...  \n",
       "146        6.291457                0.45      48.081046  13142.154622  \n",
       "147        0.000003                 0.3       0.000015      0.006267  \n",
       "148        6.291457                0.45      48.081046  13142.154622  \n",
       "149        6.291456                 1.8     2956.98432  13142.152533  \n",
       "150        6.291459                0.45      48.081046    13142.1588  \n",
       "\n",
       "[151 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder FLOPS (M)\n",
      "Private Path Encoder\n",
      "50.331648\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Private Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "201.326592\n",
      "Outsourced Path Encoder\n",
      "754.97472\n",
      "134.217728\n",
      "67.108864\n",
      "33.554432\n",
      "16.777216\n",
      "8.388608\n",
      "Outsourced Path Decoder\n",
      "33.554432\n",
      "67.108864\n",
      "134.217728\n",
      "268.435456\n",
      "536.870912\n",
      "3019.89888\n"
     ]
    }
   ],
   "source": [
    "# all locally -- 3456.172032\n",
    "# completely sourced - 3724.541952\n",
    "threshold_list = [0.3, 0.305, 0.35, 0.4, 0.42, 0.45, 0.5, 0.6, 0.63, 0.7, 1.035, 1.1, 1.2, 3.5, 5]\n",
    "# in the horizontal partitioned model, \n",
    "encoder_conv_layer_index_list_private_path = [16, 19, 22, 25, 28, 31]\n",
    "encoder_conv_layer_index_list_outsourced_path = [81, 84, 87, 90, 93, 96]\n",
    "decoder_conv_layer_index_list_private_path = [60, 63, 66, 69, 72, 75]\n",
    "decoder_conv_layer_index_list_outsourced_path = [117, 120, 123, 126, 129, 132]\n",
    "\n",
    "private_path_decode_flops_list = []\n",
    "private_path_encode_flops_list = []\n",
    "outsourced_path_encode_flops_list = []\n",
    "outsourced_path_decode_flops_list = []\n",
    "op_df_list = []\n",
    "\n",
    "for threshold in threshold_list:\n",
    "    model = DeepAppearanceVAE_Horizontal_Partition( \n",
    "        tex_size=1024,\n",
    "        mesh_inp_size=21918,\n",
    "        mode=\"vae\",\n",
    "        n_latent=128,\n",
    "        n_cams=38,\n",
    "        n_blocks=4,\n",
    "        frequency_threshold=threshold,\n",
    "        average_texture_path=\"/home/jianming/work/multiface/dataset/m--20180227--0000--6795937--GHS/unwrapped_uv_1024/E001_Neutral_Eyes_Open/average/000102.png\",\n",
    "        prefix_path_captured_latent_code=\"/home/jianming/work/Privatar_prj/testing_results/horizontal_partition_\",\n",
    "        path_variance_matrix_tensor=\"/home/jianming/work/Privatar_prj/profiled_latent_code/statistics/noise_variance_matrix_horizontal_partition_0_mutual_bound_1.pth\",\n",
    "        save_latent_code_to_external_device = False,\n",
    "        apply_gaussian_noise = False,\n",
    "        res=False,\n",
    "        non=False,\n",
    "        bilinear=False)\n",
    "\n",
    "    embed_size = 512\n",
    "    num_tokens = 30\n",
    "    unit = Unit()\n",
    "    system = System(\n",
    "        unit,\n",
    "        frequency=940,\n",
    "        flops=123,\n",
    "        onchip_mem_bw=900,\n",
    "        pe_min_density_support=0.0001,\n",
    "        accelerator_type=\"structured\",\n",
    "        model_on_chip_mem_implications=False,\n",
    "        on_chip_mem_size=32,\n",
    "    )\n",
    "\n",
    "    # model.private_idx, model.public_idx\n",
    "    inputs = (\n",
    "        torch.randn([1, 3, 1024, 1024]),\n",
    "        torch.randn([1, 7306, 3]),\n",
    "        torch.randn([1, 3]),\n",
    "        torch.randn([1]).to(torch.long),\n",
    "    )\n",
    "\n",
    "    # macs = profile_macs(model, inputs)\n",
    "    # print('transformer: {:.4g} G'.format(macs / 1e9))\n",
    "    op_df = profiler(model, inputs, system, unit)\n",
    "    display(op_df)\n",
    "    \n",
    "    op_df_list.append(op_df)\n",
    "    \n",
    "    op_df.to_csv(f\"hp_{threshold}.csv\")\n",
    "    print(\"encoder FLOPS (M)\")\n",
    "\n",
    "    print(\"Private Path Encoder\")\n",
    "    private_path_encode_flops = []\n",
    "    for conv_layer_index in encoder_conv_layer_index_list_private_path:\n",
    "        print(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "        private_path_encode_flops.append(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "\n",
    "    print(\"Private Path Decoder\")\n",
    "    private_path_decode_flops = []\n",
    "    for conv_layer_index in decoder_conv_layer_index_list_private_path:\n",
    "        print(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "        private_path_decode_flops.append(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "\n",
    "    print(\"Outsourced Path Encoder\")\n",
    "    outsourced_path_encode_flops = []\n",
    "    for conv_layer_index in encoder_conv_layer_index_list_outsourced_path:\n",
    "        print(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "        outsourced_path_encode_flops.append(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "\n",
    "    print(\"Outsourced Path Decoder\")\n",
    "    outsourced_path_decode_flops = []\n",
    "    for conv_layer_index in decoder_conv_layer_index_list_outsourced_path:\n",
    "        print(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "        outsourced_path_decode_flops.append(op_df['Flops (MFLOP)'][conv_layer_index])\n",
    "\n",
    "    private_path_decode_flops_list.append(private_path_decode_flops)\n",
    "    private_path_encode_flops_list.append(private_path_encode_flops)\n",
    "    outsourced_path_encode_flops_list.append(outsourced_path_encode_flops)\n",
    "    outsourced_path_decode_flops_list.append(outsourced_path_decode_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold list\n",
      "[0.3, 0.305, 0.35, 0.4, 0.42, 0.45, 0.5, 0.6, 0.63, 0.7, 1.035, 1.1, 1.2, 3.5, 5]\n",
      "Local Computation\n",
      "[[754.97472, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [704.643072, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [654.311424, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [603.979776, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [553.648128, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [503.31648, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [452.984832, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [402.653184, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [352.321536, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [301.989888, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [301.989888, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [201.326592, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [150.994944, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [100.663296, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [50.331648, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608]]\n",
      "[[33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 3019.89888], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2818.572288], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2617.245696], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2415.919104], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2214.592512], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2013.26592], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1811.939328], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1610.612736], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1409.286144], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1207.959552], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1207.959552], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 805.306368], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 603.979776], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 402.653184], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 201.326592]]\n",
      "Outsourced Computation\n",
      "[[50.331648, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [100.663296, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [150.994944, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [201.326592, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [251.65824, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [301.989888, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [352.321536, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [402.653184, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [452.984832, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [503.31648, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [503.31648, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [603.979776, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [654.311424, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [704.643072, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608], [754.97472, 134.217728, 67.108864, 33.554432, 16.777216, 8.388608]]\n",
      "[[33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 201.326592], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 402.653184], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 603.979776], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 805.306368], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1006.63296], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1207.959552], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1409.286144], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1610.612736], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 1811.939328], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2013.26592], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2013.26592], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2415.919104], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2617.245696], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 2818.572288], [33.554432, 67.108864, 134.217728, 268.435456, 536.870912, 3019.89888]]\n"
     ]
    }
   ],
   "source": [
    "# local computation\n",
    "print(\"threshold list\")\n",
    "threshold_list = [0.3, 0.305, 0.35, 0.4, 0.42, 0.45, 0.5, 0.6, 0.63, 0.7, 1.035, 1.1, 1.2, 3.5, 5]\n",
    "\n",
    "print(threshold_list)\n",
    "\n",
    "print(\"Local Computation\")\n",
    "print(private_path_encode_flops_list)\n",
    "print(private_path_decode_flops_list)\n",
    "\n",
    "# Outsourced computation\n",
    "print(\"Outsourced Computation\")\n",
    "print(outsourced_path_encode_flops_list)\n",
    "print(outsourced_path_decode_flops_list)\n",
    "\n",
    "private_path_encode_flops_sum_list = []\n",
    "private_path_decode_flops_sum_list = []\n",
    "outsourced_path_encode_flops_sum_list = []\n",
    "outsourced_path_decode_flops_sum_list = []\n",
    "\n",
    "for i in range(len(private_path_encode_flops_list)):\n",
    "    private_path_encode_flops_sum_list.append(np.sum(private_path_encode_flops_list[i]))\n",
    "    private_path_decode_flops_sum_list.append(np.sum(private_path_decode_flops_list[i]))\n",
    "    outsourced_path_encode_flops_sum_list.append(np.sum(outsourced_path_encode_flops_list[i]))\n",
    "    outsourced_path_decode_flops_sum_list.append(np.sum(outsourced_path_decode_flops_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Computation\n",
      "[1015.021568, 964.6899199999999, 914.3582719999999, 864.026624, 813.694976, 763.363328, 713.0316799999999, 662.700032, 612.368384, 562.0367359999999, 562.0367359999999, 461.37343999999996, 411.041792, 360.710144, 310.378496]\n",
      "[4060.086272, 3858.7596799999997, 3657.4330879999998, 3456.106496, 3254.779904, 3053.4533119999996, 2852.1267199999998, 2650.800128, 2449.4735359999995, 2248.146944, 2248.146944, 1845.4937599999998, 1644.167168, 1442.8405759999998, 1241.5139839999997]\n",
      "Outsourced Computation\n",
      "[310.378496, 360.710144, 411.041792, 461.37343999999996, 511.705088, 562.0367359999999, 612.368384, 662.700032, 713.0316799999999, 763.363328, 763.363328, 864.026624, 914.3582719999999, 964.6899199999999, 1015.021568]\n",
      "[1241.5139839999997, 1442.8405759999998, 1644.167168, 1845.4937599999998, 2046.8203519999997, 2248.146944, 2449.4735359999995, 2650.800128, 2852.1267199999998, 3053.4533119999996, 3053.4533119999996, 3456.106496, 3657.4330879999998, 3858.7596799999997, 4060.086272]\n"
     ]
    }
   ],
   "source": [
    "print(\"Local Computation\")\n",
    "print(private_path_encode_flops_sum_list)\n",
    "print(private_path_decode_flops_sum_list)\n",
    "\n",
    "print(\"Outsourced Computation\")\n",
    "print(outsourced_path_encode_flops_sum_list)\n",
    "print(outsourced_path_decode_flops_sum_list)\n",
    "\n",
    "private_path_encode_flops_sum_list_array = np.array(private_path_encode_flops_sum_list)\n",
    "private_path_decode_flops_sum_list_array = np.array(private_path_decode_flops_sum_list)\n",
    "outsourced_path_encode_flops_sum_list_array = np.array(outsourced_path_encode_flops_sum_list)\n",
    "outsourced_path_decode_flops_sum_list_array = np.array(outsourced_path_decode_flops_sum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1015.021568,\n",
       " 964.6899199999999,\n",
       " 914.3582719999999,\n",
       " 864.026624,\n",
       " 813.694976,\n",
       " 763.363328,\n",
       " 713.0316799999999,\n",
       " 662.700032,\n",
       " 612.368384,\n",
       " 562.0367359999999,\n",
       " 562.0367359999999,\n",
       " 461.37343999999996,\n",
       " 411.041792,\n",
       " 360.710144,\n",
       " 310.378496]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_path_encode_flops_sum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_path_decode_flops_sum_list_array\n",
    "array_list = private_path_decode_flops_sum_list_array.tolist()\n",
    "    \n",
    "# Inject the element at the specified index\n",
    "# array_list.insert(0, 3456.172032)\n",
    "# all locally -- 3456.172032\n",
    "# completely sourced - 3724.541952\n",
    "\n",
    "# Convert the list back to a numpy array\n",
    "private_path_decode_flops_sum_list_array = np.array(array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder latency\n",
      "local decoder compute latency (s) = [0.00386675 0.00367501 0.00348327 0.00329153 0.00309979 0.00290805\n",
      " 0.00271631 0.00252457 0.00233283 0.00214109 0.00214109 0.00175761\n",
      " 0.00156587 0.00137413 0.00118239]\n",
      "outsourced decoder compute latency (s) = [2.06918997e-06 2.40473429e-06 2.74027861e-06 3.07582293e-06\n",
      " 3.41136725e-06 3.74691157e-06 4.08245589e-06 4.41800021e-06\n",
      " 4.75354453e-06 5.08908885e-06 5.08908885e-06 5.76017749e-06\n",
      " 6.09572181e-06 6.43126613e-06 6.76681045e-06]\n",
      "Achievable FPS\n",
      "local decoder FPS (frame/s) = [258.61519427 272.10816093 287.08659181 303.81008259 322.60245884\n",
      " 343.87295063 368.14633538 396.10681655 428.66354119 467.051321\n",
      " 467.051321   568.9534274  638.62119402 727.73112807 845.74158127]\n",
      "outsourced decoder FPS (frame/s) = [483280.90358425 415846.35889807 364926.39658402 325116.2442294\n",
      " 293137.59725602 266886.46914354 244950.59496736 226346.75231161\n",
      " 210369.33450138 196498.82892986 196498.82892986 173605.76148172\n",
      " 164049.48103319 155490.37767493 147780.11101337]\n"
     ]
    }
   ],
   "source": [
    "utilization = 0.6\n",
    "# available_local_compute = 14 * 1000000 * 0.3\n",
    "available_local_compute = 1.75 * 1000000\n",
    "available_outsourced_compute = 1000 * 1000000\n",
    "\n",
    "print(\"decoder latency\")\n",
    "local_computation_latency = private_path_decode_flops_sum_list_array / (available_local_compute * utilization)\n",
    "outsourced_computation_latency = outsourced_path_decode_flops_sum_list_array / (available_outsourced_compute * utilization)\n",
    "print(f\"local decoder compute latency (s) = {local_computation_latency}\")\n",
    "print(f\"outsourced decoder compute latency (s) = {outsourced_computation_latency}\")\n",
    "\n",
    "print(\"Achievable FPS\")\n",
    "print(f\"local decoder FPS (frame/s) = {1/local_computation_latency}\")\n",
    "print(f\"outsourced decoder FPS (frame/s) = {1/outsourced_computation_latency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communication latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "1.5\n",
      "2.25\n",
      "3.0\n",
      "3.75\n",
      "4.5\n",
      "5.25\n",
      "6.0\n",
      "6.75\n",
      "7.5\n",
      "7.5\n",
      "9.0\n",
      "9.75\n",
      "10.5\n",
      "11.25\n"
     ]
    }
   ],
   "source": [
    "final_res_index = 132\n",
    "communication_list = []\n",
    "for op_df in op_df_list:\n",
    "    print(np.prod(op_df['Output'][final_res_index])*32/8/1024/1024)\n",
    "    communication_list.append(np.prod(op_df['Output'][final_res_index])*32/8/1024/1024)\n",
    "    # print(op_df['Output (MB)'][final_res_index])\n",
    "    # communication_list.append(op_df['Output (MB)'][final_res_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "communication latency -- FPS\n",
      "[3333.33333333 1666.66666667 1111.11111111  833.33333333  666.66666667\n",
      "  555.55555556  476.19047619  416.66666667  370.37037037  333.33333333\n",
      "  333.33333333  277.77777778  256.41025641  238.0952381   222.22222222]\n",
      "[0.0003 0.0006 0.0009 0.0012 0.0015 0.0018 0.0021 0.0024 0.0027 0.003\n",
      " 0.003  0.0036 0.0039 0.0042 0.0045]\n"
     ]
    }
   ],
   "source": [
    "print(\"communication latency -- FPS\")\n",
    "communication_bandwidth = 20 * (10 ** 3) / 8 # Gbps\n",
    "communication_latency = np.array(communication_list) / communication_bandwidth\n",
    "communication_FPS = 1 /communication_latency\n",
    "print(communication_FPS)\n",
    "print(communication_latency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original Model -- complete data outsourcing\n",
    "\n",
    "# decoder FLOPS (M)\n",
    "# 134.217728\n",
    "# 134.217728\n",
    "# 134.217728\n",
    "# 268.435456\n",
    "# 536.870912\n",
    "# 1073.741824\n",
    "# 2147.483648\n",
    "# 1610.612736\n",
    "# [134.217728, 134.217728, 134.217728, 268.435456, 536.870912, 1073.741824, 2147.483648, 1610.612736]\n",
    "# 6039.7977599999995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(local_computation_latency))\n",
    "print(len(communication_latency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00386675 0.00367501 0.00348327 0.00329153 0.00309979 0.00290805\n",
      " 0.00271631 0.00252457 0.00233283 0.00214109 0.00214109 0.00175761\n",
      " 0.00156587 0.00137413 0.00118239]\n",
      "[0.0003 0.0006 0.0009 0.0012 0.0015 0.0018 0.0021 0.0024 0.0027 0.003\n",
      " 0.003  0.0036 0.0039 0.0042 0.0045]\n"
     ]
    }
   ],
   "source": [
    "print(local_computation_latency)\n",
    "print(communication_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "shape_list = [\"o\", \"*\", \"X\", \"p\", \">\", \"d\", \"s\", \"H\", \"<\"]\n",
    "legend_list = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "color_list = [\"#B46504\", \"#23445D\", \"#D79B00\", \"#D6B656\", \"#B85450\", \"#9673A6\", \"#6C8EBF\", \"#82B366\"]\n",
    "\n",
    "# create data\n",
    "fig = plt.figure(figsize=[10,5.5])\n",
    "ax = plt.subplot(111)\n",
    "# threshold_list = [0.3, 0.305, 0.35, 0.4, 0.42, 0.45, 0.5, 0.6, 0.63, 0.7, 1.035, 1.1, 1.2, 3.5, 5]\n",
    "threshold_list = [i for i in range(15)]\n",
    "# x_list = [i for i in range(len(threshold_list))]\n",
    "ax.plot(threshold_list, local_computation_latency*1000, marker=shape_list[0], markerfacecolor=color_list[0], markersize=10, color=color_list[0], linewidth=2)\n",
    "ax.plot(threshold_list, communication_latency*1000, marker=shape_list[1], markerfacecolor=color_list[1], markersize=10, color=color_list[1], linewidth=2, linestyle='--')\n",
    "ax.plot([0, 15], [local_computation_latency[0]*1000, local_computation_latency[0]*1000], markersize=0, color=color_list[2], linewidth=2, linestyle='-.')\n",
    "ax.plot([0, 15], [6039.7977599999995/1000, 6039.7977599999995/1000], markersize=0, color=color_list[4], linewidth=2, linestyle=':')\n",
    "\n",
    "SMALL_SIZE = 18\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.ylabel(\"Latency (ms)\", fontsize=SMALL_SIZE)\n",
    "plt.xlabel(\"number of outsourced components\", fontsize=SMALL_SIZE)\n",
    "label_xticks = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "plt.xticks(label_xticks, [str(label_xtick) for label_xtick in label_xticks], fontsize=MEDIUM_SIZE)\n",
    "# plt.title(\"Scores by Teams in 4 Rounds\")\n",
    "\n",
    "# plt.legend([\"zcu104\", 'Alveo U280'])#, fontsize=SMALL_SIZE)\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "\n",
    "plt.legend([\"compute latency\", \"communication latency\", \"BDCT All Local\" , \"VAE [16]\"], loc='right',  bbox_to_anchor=(0.95, 0.83), fontsize=SMALL_SIZE, ncol=2, labelspacing = 0)#, bbox_to_anchor=(1.3, 0.5), fontsize=SMALL_SIZE)\n",
    "# plt.legend(plt_handler, [\"Computer Energy\", \"Off-chip Data Access Energy\", \"On-chip Data Access Energy\"], loc='lower center', bbox_to_anchor=(0.5, -0.35), fontsize=MEDIUM_SIZE)\n",
    "plt.savefig('communi_compute_latency_block_4x4_new.pdf', bbox_inches=\"tight\", transparent=True) \n",
    "\n",
    "plt.annotate(text=\"\", xy=(7, 1), xytext=(7, 2.2), color=\"red\", arrowprops=dict(arrowstyle='<-, head_length=1',  linewidth=2.5, color=color_list[6]))\n",
    "plt.text(7, 0.8, \"Optimal Division Point\", rotation = 0, fontsize=17, color=\"k\", horizontalalignment='center', verticalalignment='center')\n",
    "plt.savefig('communi_compute_latency_block_4x4.pdf', bbox_inches=\"tight\", transparent=True) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_latency = []\n",
    "for i in range(len(communication_latency)):\n",
    "    if (communication_latency[i] > local_computation_latency[i]):\n",
    "        overall_latency.append(communication_latency[i])\n",
    "    else:\n",
    "        overall_latency.append(local_computation_latency[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 5, 5, 5, 6, 6, 7, 7, 7, 9, 10, 12, 14]\n",
      "[34, 36, 38, 40, 43, 45, 49, 52, 57, 62, 62, 75, 85, 97, 112]\n",
      "[55, 27, 18, 13, 11, 9, 7, 6, 6, 5, 5, 4, 4, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "FPS_local_comp_quest_2_list = [math.floor(1/latency/60) for latency in local_computation_latency]\n",
    "FPS_local_comp_quest_pro_list = [math.floor(1/latency*8/60) for latency in local_computation_latency]\n",
    "FPS_local_comm_list = [math.floor(1/latency/60) for latency in communication_latency]\n",
    "print(FPS_local_comp_quest_2_list)\n",
    "print(FPS_local_comp_quest_pro_list)\n",
    "print(FPS_local_comm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_label_list = [f\"{latency*1000:.02f}\" for latency in overall_latency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3.87', '3.68', '3.48', '3.29', '3.10', '2.91', '2.72', '2.52', '2.70', '3.00', '3.00', '3.60', '3.90', '4.20', '4.50']\n"
     ]
    }
   ],
   "source": [
    "print(latency_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_successful_rate_list_mutual_info_list = np.array([[0.017557251908396947, 0.017557251908396947, 0.017557251908396947, 0.017557251908396947, 0.017557251908396947, 0.017557251908396947, 0.025114503816793893, 0.025114503816793893, 0.025114503816793893, 0.025114503816793893, 0.03267175572519084, 0.11725190839694656, 0.13221374045801526, 0.18458015267175573, 0.32671755725190843, 1],\n",
    " [0.05725190839694656, 0.05725190839694656, 0.05725190839694656, 0.05725190839694656, 0.05725190839694656, 0.05725190839694656, 0.07435114503816793, 0.07435114503816793, 0.07435114503816793, 0.07435114503816793, 0.08152671755725191, 0.1803053435114504, 0.19419847328244275, 0.2511450381679389, 0.4022900763358779, 1],\n",
    " [0.28549618320610687, 0.28549618320610687, 0.28549618320610687, 0.28549618320610687, 0.28549618320610687, 0.28549618320610687, 0.330381679389313, 0.330381679389313, 0.330381679389313, 0.330381679389313, 0.3648854961832061, 0.5766412213740457, 0.610381679389313, 0.7004580152671755, 0.9244274809160307, 1],\n",
    " [0.48396946564885496, 0.48396946564885496, 0.48396946564885496, 0.48396946564885496, 0.48396946564885496, 0.48396946564885496, 0.5568702290076336, 0.5568702290076336, 0.5568702290076336, 0.5568702290076336, 0.6189312977099237, 0.9099236641221373, 0.9468702290076335, 1, 1, 1]])\n",
    "posterior_successful_rate_list_mutual_info_list = np.transpose(posterior_successful_rate_list_mutual_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_successful_rate_list_mutual_info_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prior_successful_rate_list = [1.0, 0.31297709923664124, 0.16793893129770993, 0.11450381679389313, 0.09923664122137404, 0.022900763358778626, 0.015267175572519083, 0.015267175572519083, 0.015267175572519083, 0.015267175572519083, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542]\n",
    "# prior_successful_rate_list = prior_successful_rate_list[::-1]\n",
    "\n",
    "fig = plt.figure(figsize=[12,5.5])\n",
    "# fig = plt.figure(figsize=[7,5.5])\n",
    "ax = plt.subplot(111)\n",
    "x = [i for i in range(len(prior_successful_rate_list))]\n",
    "prior_successful_rate_list = prior_successful_rate_list[::-1]\n",
    "plt.bar(x, prior_successful_rate_list, color=\"#990000\")\n",
    "\n",
    "SMALL_SIZE = 18\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.ylabel(\"Empirical Successful Rate\", fontsize=SMALL_SIZE)\n",
    "plt.xlabel(\"number of outsourced frequency components\", fontsize=SMALL_SIZE)\n",
    "# plt.xticks([i for i in range(int(max(tflop_list)+1))], [str(i) for i in range(int(max(tflop_list)+1))], fontsize=MEDIUM_SIZE)\n",
    "# plt.title(\"Scores by Teams in 4 Rounds\")\n",
    "\n",
    "# plt.legend([\"zcu104\", 'Alveo U280'])#, fontsize=SMALL_SIZE)\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "\n",
    "plt.savefig('empirical_successful_rate.pdf', bbox_inches=\"tight\", transparent=True) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prior_successful_rate_list = [1.0, 0.31297709923664124, 0.16793893129770993, 0.11450381679389313, 0.09923664122137404, 0.022900763358778626, 0.015267175572519083, 0.015267175572519083, 0.015267175572519083, 0.015267175572519083, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542, 0.007633587786259542]\n",
    "# prior_successful_rate_list = prior_successful_rate_list[::-1]\n",
    "\n",
    "fig = plt.figure(figsize=[7,5.5])\n",
    "ax = plt.subplot(111)\n",
    "x = [i for i in range(len(prior_successful_rate_list))]\n",
    "prior_successful_rate_list = prior_successful_rate_list[::-1]\n",
    "plt.plot(x, prior_successful_rate_list, color=\"#990000\", marker=\".\", markerfacecolor=\"#ffffff\", markersize=16, linewidth=2, markeredgewidth=4)\n",
    "\n",
    "SMALL_SIZE = 18\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 22\n",
    "\n",
    "plt.ylabel(\"L2 Norm bound\", fontsize=SMALL_SIZE)\n",
    "plt.xlabel(\"Accuracy (Loss)\", fontsize=SMALL_SIZE)\n",
    "# plt.xticks([i for i in range(int(max(tflop_list)+1))], [str(i) for i in range(int(max(tflop_list)+1))], fontsize=MEDIUM_SIZE)\n",
    "# plt.title(\"Scores by Teams in 4 Rounds\")\n",
    "\n",
    "# plt.legend([\"zcu104\", 'Alveo U280'])#, fontsize=SMALL_SIZE)\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "\n",
    "plt.savefig('L2_norm_under_various_accuracy.pdf', bbox_inches=\"tight\", transparent=True) \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
